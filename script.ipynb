{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import Library"
      ],
      "metadata": {
        "id": "Jkf1QbWuo-Ol"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoG1ffFpo6Hq"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from PIL import Image\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from keras.preprocessing import image"
      ],
      "metadata": {
        "id": "w7DOyHVLpNnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Model\n",
        "\n",
        "- Initialising the CNN\n",
        "- Convolution\n",
        "- Pooling\n",
        "- Flattening\n",
        "- Full connection"
      ],
      "metadata": {
        "id": "_bNdOem1phTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Initialising the CNN\n",
        "classifier = Sequential()\n",
        "\n",
        "# 2. Convolution\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
        "\n",
        "# 3. Pooling\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# 4. Flattening\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# 5. Full connection\n",
        "classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "classifier.add(Dense(units = 1, activation = 'sigmoid'))  # Output layer for binary classification\n"
      ],
      "metadata": {
        "id": "C6VdU4J2picT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Compile"
      ],
      "metadata": {
        "id": "XLf5qeRQqCYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "xlCs8YqLqJ61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Augmentation & Model Fit"
      ],
      "metadata": {
        "id": "Ck0E7UqmqUmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an object of ImageDataGenerator, for augmenting train set\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True\n",
        ")\n",
        "\n",
        "# Create another object of ImageDataGenerator, for augmenting test set\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "# Apply image augmentation on train set\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "    'D:/Data Olah/catdog/training_set',\n",
        "    target_size = (64, 64),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'binary'\n",
        ")\n",
        "\n",
        "# Apply image augmentation on test set\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    'D:/Data Olah/catdog/test_set',\n",
        "    target_size = (64, 64),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'binary'\n",
        ")\n",
        "\n",
        "# Train the CNN model\n",
        "classifier.fit(\n",
        "    training_set,\n",
        "    steps_per_epoch = (8000 // 32),\n",
        "    epochs = 25,\n",
        "    validation_data = test_set,\n",
        "    validation_steps = (2000 // 32)\n",
        ")"
      ],
      "metadata": {
        "id": "wSFXHLsyqVSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OJhaGS-Ao8m8"
      }
    }
  ]
}
